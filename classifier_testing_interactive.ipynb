{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6d076e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/claudiac/Library/CloudStorage/OneDrive-WashingtonUniversityinSt.Louis/social_behavior_classifier\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "90c44486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDW_classifier_testing-Copy1.ipynb     \u001b[34mcorpora-sentences\u001b[m\u001b[m\r\n",
      "\u001b[31mHDW_classifier_testing.ipynb\u001b[m\u001b[m           \u001b[34mdescription_classifier\u001b[m\u001b[m\r\n",
      "\u001b[31mHDW_final_training.csv\u001b[m\u001b[m                 \u001b[31mprepping_training_data.ipynb\u001b[m\u001b[m\r\n",
      "HDW_final_training.xlsx                \u001b[31mrealism_bibliography.xlsx\u001b[m\u001b[m\r\n",
      "\u001b[31mUntitled-laptop’s MacBook Air.ipynb\u001b[m\u001b[m    \u001b[31mrealism_bibliography_instructions.docx\u001b[m\u001b[m\r\n",
      "\u001b[31mannotation tags.docx\u001b[m\u001b[m                   test1.csv\r\n",
      "\u001b[31mapplying_fine-tuned_classifier.ipynb\u001b[m\u001b[m   test2_accuracy_scores.docx\r\n",
      "austen_test_data.xlsx                  \u001b[34mtraining data\u001b[m\u001b[m\r\n",
      "\u001b[34mclassifier_testing\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2f515c",
   "metadata": {},
   "source": [
    "## Setting test name and hyperparameters ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "acb61b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_name = \"test4\"\n",
    "\n",
    "#Test hyperparameters\n",
    "num_classes = 3\n",
    "max_length = 512\n",
    "bert_model_name = 'bert-base-uncased'\n",
    "num_epochs = 5\n",
    "learning_rate = 2e-5\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fe1bf3",
   "metadata": {},
   "source": [
    "## Imports ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "6fd6f08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "91dde6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "773d25b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "248b1159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c307d7",
   "metadata": {},
   "source": [
    "## Prepping training data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "3e72ada0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>eric_category</th>\n",
       "      <th>lucia_category</th>\n",
       "      <th>sada_category</th>\n",
       "      <th>filename_x</th>\n",
       "      <th>sub-categories</th>\n",
       "      <th>embedded?</th>\n",
       "      <th>notes</th>\n",
       "      <th>interaction?</th>\n",
       "      <th>...</th>\n",
       "      <th>? / Secondary</th>\n",
       "      <th>Interaction</th>\n",
       "      <th>Embedded</th>\n",
       "      <th>filename_y</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>interactive</th>\n",
       "      <th>embedded</th>\n",
       "      <th>Questionable</th>\n",
       "      <th>filename</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>That evening Mr. Utterson came home to his bac...</td>\n",
       "      <td>mental</td>\n",
       "      <td>mental</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stevenson-jekyl-1886.txt</td>\n",
       "      <td>emotion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It offended him both as a lawyer and as a love...</td>\n",
       "      <td>mental</td>\n",
       "      <td>mental</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stevenson-jekyl-1886.txt</td>\n",
       "      <td>emotion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>It was a night of little ease to his toiling m...</td>\n",
       "      <td>mental</td>\n",
       "      <td>mental</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stevenson-jekyl-1886.txt</td>\n",
       "      <td>emotion; thought</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>But his fear was only momentary.</td>\n",
       "      <td>mental</td>\n",
       "      <td>mental</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stevenson-jekyl-1886.txt</td>\n",
       "      <td>emotion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Cried Mr. Hyde, with a flush of anger.</td>\n",
       "      <td>mental</td>\n",
       "      <td>mental</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stevenson-jekyl-1886.txt</td>\n",
       "      <td>emotion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  \\\n",
       "0           0  That evening Mr. Utterson came home to his bac...   \n",
       "1           1  It offended him both as a lawyer and as a love...   \n",
       "2           2  It was a night of little ease to his toiling m...   \n",
       "3           4                   But his fear was only momentary.   \n",
       "4           5             Cried Mr. Hyde, with a flush of anger.   \n",
       "\n",
       "  eric_category lucia_category sada_category                filename_x  \\\n",
       "0        mental         mental           NaN  stevenson-jekyl-1886.txt   \n",
       "1        mental         mental           NaN  stevenson-jekyl-1886.txt   \n",
       "2        mental         mental           NaN  stevenson-jekyl-1886.txt   \n",
       "3        mental         mental           NaN  stevenson-jekyl-1886.txt   \n",
       "4        mental         mental           NaN  stevenson-jekyl-1886.txt   \n",
       "\n",
       "     sub-categories embedded? notes interaction?  ... ? / Secondary  \\\n",
       "0           emotion       NaN   NaN          NaN  ...           NaN   \n",
       "1           emotion       NaN   NaN          NaN  ...           NaN   \n",
       "2  emotion; thought       NaN   NaN          NaN  ...           NaN   \n",
       "3           emotion       NaN   NaN          NaN  ...           NaN   \n",
       "4           emotion       NaN   NaN          NaN  ...           NaN   \n",
       "\n",
       "  Interaction Embedded filename_y subcategory interactive embedded  \\\n",
       "0         NaN      NaN        NaN         NaN         NaN      NaN   \n",
       "1         NaN      NaN        NaN         NaN         NaN      NaN   \n",
       "2         NaN      NaN        NaN         NaN         NaN      NaN   \n",
       "3         NaN      NaN        NaN         NaN         NaN      NaN   \n",
       "4         NaN      NaN        NaN         NaN         NaN      NaN   \n",
       "\n",
       "  Questionable filename Unnamed: 13  \n",
       "0          NaN      NaN         NaN  \n",
       "1          NaN      NaN         NaN  \n",
       "2          NaN      NaN         NaN  \n",
       "3          NaN      NaN         NaN  \n",
       "4          NaN      NaN         NaN  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df = pd.read_excel(\"training data/classifier_annotations/2way_cross_validated.xlsx\")\n",
    "    \n",
    "original_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "52f0af85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6412 entries, 0 to 6411\n",
      "Data columns (total 22 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Unnamed: 0      6412 non-null   int64 \n",
      " 1   text            6412 non-null   object\n",
      " 2   eric_category   6409 non-null   object\n",
      " 3   lucia_category  6410 non-null   object\n",
      " 4   sada_category   2770 non-null   object\n",
      " 5   filename_x      1660 non-null   object\n",
      " 6   sub-categories  1660 non-null   object\n",
      " 7   embedded?       51 non-null     object\n",
      " 8   notes           50 non-null     object\n",
      " 9   interaction?    138 non-null    object\n",
      " 10  Unnamed: 4      4 non-null      object\n",
      " 11  Subcategory     1368 non-null   object\n",
      " 12  ? / Secondary   141 non-null    object\n",
      " 13  Interaction     21 non-null     object\n",
      " 14  Embedded        8 non-null      object\n",
      " 15  filename_y      1888 non-null   object\n",
      " 16  subcategory     2308 non-null   object\n",
      " 17  interactive     77 non-null     object\n",
      " 18  embedded        44 non-null     object\n",
      " 19  Questionable    37 non-null     object\n",
      " 20  filename        2770 non-null   object\n",
      " 21  Unnamed: 13     1 non-null      object\n",
      "dtypes: int64(1), object(21)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "original_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d5546a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "#Finding number of texts from which current training data is taken\n",
    "\n",
    "a = original_df['filename'].nunique(dropna=True)\n",
    "b = original_df['filename_x'].nunique(dropna=True)\n",
    "c = original_df['filename_y'].nunique(dropna=True)\n",
    "no_of_texts = a+b+c\n",
    "print(no_of_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "7348a8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a cleaned up dataframe for training\n",
    "\n",
    "index1 = []\n",
    "\n",
    "for index, row in original_df.iterrows():\n",
    "    values = [row['eric_category'], row['lucia_category'], row['sada_category']]\n",
    "    common_label = None\n",
    "    \n",
    "    # Find the label that appears at least twice\n",
    "    for value in set(values):\n",
    "        if values.count(value) >= 2:\n",
    "            common_label = value\n",
    "            break\n",
    "    \n",
    "    # If a common label is found, save it and the 'text' column to the list\n",
    "    if common_label:\n",
    "        index1.append({'text': row['text'], 'category': common_label})\n",
    "\n",
    "# Create a new dataframe from the list of rows\n",
    "df = pd.DataFrame(index1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "30c95fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That evening Mr. Utterson came home to his bac...</td>\n",
       "      <td>mental</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It offended him both as a lawyer and as a love...</td>\n",
       "      <td>mental</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It was a night of little ease to his toiling m...</td>\n",
       "      <td>mental</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>But his fear was only momentary.</td>\n",
       "      <td>mental</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cried Mr. Hyde, with a flush of anger.</td>\n",
       "      <td>mental</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text category\n",
       "0  That evening Mr. Utterson came home to his bac...   mental\n",
       "1  It offended him both as a lawyer and as a love...   mental\n",
       "2  It was a night of little ease to his toiling m...   mental\n",
       "3                   But his fear was only momentary.   mental\n",
       "4             Cried Mr. Hyde, with a flush of anger.   mental"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "02bd1c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6412 entries, 0 to 6411\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   text      6412 non-null   object\n",
      " 1   category  6412 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 100.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "433e3f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mental', 'behavior', 'other'], dtype=object)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity check\n",
    "\n",
    "df['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "0b00ad7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting number of training samples for each class\n",
    "\n",
    "count_behavior = (df['category'] == 'behavior').sum()\n",
    "count_mental = (df['category'] == 'mental').sum()\n",
    "count_other = (df['category'] == 'other').sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "ab38f8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating lists of training texts and numeric designations for classes\n",
    "\n",
    "texts = df['text'].tolist()\n",
    "\n",
    "designation_numeric = []\n",
    "\n",
    "#df['designation']\n",
    "\n",
    "for x in df['category']:\n",
    "    if x == 'other':\n",
    "        designation_numeric.append(0)\n",
    "    elif x == 'mental':\n",
    "        designation_numeric.append(1)\n",
    "    elif x == 'behavior':\n",
    "        designation_numeric.append(2)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "efb7cdbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.tensor(designation_numeric)\n",
    "type(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "119a956d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6412"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity check\n",
    "len(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "9e1fa8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6412"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ac9c44",
   "metadata": {},
   "source": [
    "## Setting up classes and functions for classifier ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4aa00012",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a class (object and set of associate functions) to store the training data in a certain structure,\n",
    "# and also query the training and output data. Class consists of the input texts, their integer labels, the BERT\n",
    "# tokenizer used to prep the data for feeding to the classifier, and the max input length the model will take. \n",
    "#This class is a child class of the Pytorch \"torch.utils.data.Dataset\" parent/base class\n",
    "#Sentences longer than the max input length will be truncated and the remainder discarded!\n",
    "\n",
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(text, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n",
    "        return {'input_ids': encoding['input_ids'].flatten(), 'attention_mask': encoding['attention_mask'].flatten(), 'label': torch.tensor(label)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "4eecc8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self, bert_model_name, num_classes):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        x = self.dropout(pooled_output)\n",
    "        logits = self.fc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "194d433d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    for batch in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "1eafe4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actual_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            predictions.extend(preds.cpu().tolist())\n",
    "            actual_labels.extend(labels.cpu().tolist())\n",
    "    return accuracy_score(actual_labels, predictions), classification_report(actual_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "178d7c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_description(text, model, tokenizer, device, max_length):\n",
    "    model.eval()\n",
    "    encoding = tokenizer(text, return_tensors='pt', max_length=max_length, padding='max_length', truncation=True)\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "    label_map = {0: \"null\", 1: \"mental\", 2: \"behaviour\"}\n",
    "    return label_map[preds.item()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "83cce6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables to save results. \n",
    "\n",
    "file_name = test_name + \"_accuracy_scores.docx\"\n",
    "classifier_name = \"bert_classifier_\" + test_name + \".pth\"\n",
    "subdirectory = \"classifier_testing\"\n",
    "file_path = os.path.join(subdirectory, file_name)\n",
    "classifier_path = os.path.join(subdirectory, classifier_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca9a397",
   "metadata": {},
   "source": [
    "## Assigning variables for classifier training ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "cbb526b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "770d67a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/claudiac/anaconda3/lib/python3.11/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "train_dataset = TextClassificationDataset(train_texts, train_labels, tokenizer, max_length)\n",
    "val_dataset = TextClassificationDataset(val_texts, val_labels, tokenizer, max_length)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BERTClassifier(bert_model_name, num_classes).to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "total_steps = len(train_dataloader) * num_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542a0739",
   "metadata": {},
   "source": [
    "## Actually training the classifier ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9d38e45b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lt/b6dp10jj3g56rxpph0_lh75c0000gr/T/ipykernel_21201/3279962222.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': encoding['input_ids'].flatten(), 'attention_mask': encoding['attention_mask'].flatten(), 'label': torch.tensor(label)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Validation Accuracy: 0.9174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89       298\n",
      "           1       0.90      0.95      0.93       425\n",
      "           2       0.94      0.91      0.92       560\n",
      "\n",
      "    accuracy                           0.92      1283\n",
      "   macro avg       0.91      0.91      0.91      1283\n",
      "weighted avg       0.92      0.92      0.92      1283\n",
      "\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lt/b6dp10jj3g56rxpph0_lh75c0000gr/T/ipykernel_21201/3279962222.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': encoding['input_ids'].flatten(), 'attention_mask': encoding['attention_mask'].flatten(), 'label': torch.tensor(label)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9127\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.80      0.88       298\n",
      "           1       0.89      0.95      0.92       425\n",
      "           2       0.90      0.95      0.92       560\n",
      "\n",
      "    accuracy                           0.91      1283\n",
      "   macro avg       0.92      0.90      0.91      1283\n",
      "weighted avg       0.92      0.91      0.91      1283\n",
      "\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lt/b6dp10jj3g56rxpph0_lh75c0000gr/T/ipykernel_21201/3279962222.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': encoding['input_ids'].flatten(), 'attention_mask': encoding['attention_mask'].flatten(), 'label': torch.tensor(label)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91       298\n",
      "           1       0.92      0.92      0.92       425\n",
      "           2       0.93      0.94      0.93       560\n",
      "\n",
      "    accuracy                           0.92      1283\n",
      "   macro avg       0.92      0.92      0.92      1283\n",
      "weighted avg       0.92      0.92      0.92      1283\n",
      "\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lt/b6dp10jj3g56rxpph0_lh75c0000gr/T/ipykernel_21201/3279962222.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': encoding['input_ids'].flatten(), 'attention_mask': encoding['attention_mask'].flatten(), 'label': torch.tensor(label)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9252\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92       298\n",
      "           1       0.90      0.94      0.92       425\n",
      "           2       0.95      0.92      0.93       560\n",
      "\n",
      "    accuracy                           0.93      1283\n",
      "   macro avg       0.92      0.92      0.92      1283\n",
      "weighted avg       0.93      0.93      0.93      1283\n",
      "\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lt/b6dp10jj3g56rxpph0_lh75c0000gr/T/ipykernel_21201/3279962222.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': encoding['input_ids'].flatten(), 'attention_mask': encoding['attention_mask'].flatten(), 'label': torch.tensor(label)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9260\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       298\n",
      "           1       0.91      0.93      0.92       425\n",
      "           2       0.94      0.93      0.93       560\n",
      "\n",
      "    accuracy                           0.93      1283\n",
      "   macro avg       0.93      0.92      0.92      1283\n",
      "weighted avg       0.93      0.93      0.93      1283\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    train(model, train_dataloader, optimizer, scheduler, device)\n",
    "    accuracy, report = evaluate(model, val_dataloader, device)\n",
    "    if epoch == num_epochs - 1:\n",
    "        final_accuracy = accuracy\n",
    "    print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "    print(report)\n",
    "    \n",
    "    ##UPDATE FILE NAME FOR EACH TEST!\n",
    "    with open(file_path, 'a') as f:\n",
    "        f.write(report)\n",
    "        \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9672a8d8",
   "metadata": {},
   "source": [
    "## Saving classifier and hyperparameters ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "4dbc9e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), classifier_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a6dbe84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openpyxl.worksheet.worksheet.Worksheet"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openpyxl import load_workbook\n",
    "\n",
    "file_path = 'classifier_testing/classifier_testing_parameters.xlsx'\n",
    "\n",
    "# Load the workbook and select a sheet\n",
    "workbook = load_workbook(filename=file_path)\n",
    "sheet = workbook.active\n",
    "\n",
    "type(sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cfce28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the new data to be added\n",
    "training_size = len(labels)\n",
    "data = [[classifier_name, file_name, training_size, count_behavior, count_mental, count_other, bert_model_name, num_epochs, learning_rate, batch_size, max_length, final_accuracy, no_of_texts]]\n",
    "\n",
    "# Find the next empty row in the sheet\n",
    "next_row = sheet.max_row + 1\n",
    "\n",
    "# Add the new data to the sheet\n",
    "for row in data:\n",
    "    sheet.append(row)\n",
    "\n",
    "# Save the workbook\n",
    "workbook.save(filename=file_path)\n",
    "\n",
    "print(f\"Data has been added to {file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
